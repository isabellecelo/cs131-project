# cs131-project: ASL-to-English Translation System

## Team Members
- Isabelle Celo (scelo002)
- Sahana Anand (sanan036)
- Huong Le (hle116)
- Chloe Tang (ctang085)

## Project Overview
We are developing a smart camera system that captures ASL (American Sign Language) gestures in real time and translates them into written and spoken English. The system aims to support communication in the healthcare industry between ASL speakers and non-ASL speakers.

## Key Features
- Real-time ASL gesture recognition using a Logitech camera and NVIDIA Jetson Nano
- Edge computing for processing simple gestures
- Cloud processing via AWS for complex gestures
- Text and voice output
- Voice-to-ASL output using a digital character

## Technologies Used
- TensorFlow (ML models for gesture recognition)
- AWS (Cloud processing and storage)
- NVIDIA Jetson Nano (Edge processing)
- Logitech Camera (Video input)
- USB Speaker (Audio output)

## Current Progress
- System design drafted
- Component roles defined
- ML pipeline research ongoing
